{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**A)Linear regression: Single feature vs multiple features**"
      ],
      "metadata": {
        "id": "wpJDvA4Q3s5c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a.Download dataset as per your batch."
      ],
      "metadata": {
        "id": "ebWzdcdJ4IhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_excel('AirQualityUCI.xlsx')\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "DUnfTULe4Oyq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba358e1-d547-4bbd-a46c-45c07bcadb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Date', 'Time', 'CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)',\n",
            "       'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)',\n",
            "       'PT08.S5(O3)', 'T', 'RH', 'AH'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b.Preprocessing: Null value handling, standardization, replace categorical values with numeric values (e.g. 0, 1, 2 etc.)"
      ],
      "metadata": {
        "id": "G_bVr4Lh5D6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# a. Null value handling\n",
        "print(\"\\nMissing values before handling:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Handle missing values by dropping rows with any null value\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# b. Standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Select numeric columns for standardization\n",
        "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Standardize the selected numeric columns\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "\n",
        "# c. Replace categorical values with numeric values (Label Encoding)\n",
        "# Categorical values are replaced with numeric values using label encoding\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == 'object':\n",
        "        print(f\"{column} contains categorical df.\")\n",
        "# Initialize the LabelEncoder\n",
        "print(\"\\nBefore:\")\n",
        "print(df['Time'].head())\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df['Time'] = label_encoder.fit_transform(df['Time'])\n",
        "\n",
        "print(\"\\nAfter:\")\n",
        "print(df['Time'].head())\n",
        "\n",
        "# Print the dataset after preprocessing\n",
        "print(\"\\nProcessed dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "ZplCwEz25IBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447856b7-4427-40db-8880-2e40a6f22b41"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values before handling:\n",
            "Date             0\n",
            "Time             0\n",
            "CO(GT)           0\n",
            "PT08.S1(CO)      0\n",
            "NMHC(GT)         0\n",
            "C6H6(GT)         0\n",
            "PT08.S2(NMHC)    0\n",
            "NOx(GT)          0\n",
            "PT08.S3(NOx)     0\n",
            "NO2(GT)          0\n",
            "PT08.S4(NO2)     0\n",
            "PT08.S5(O3)      0\n",
            "T                0\n",
            "RH               0\n",
            "AH               0\n",
            "dtype: int64\n",
            "\n",
            "Before:\n",
            "0    0.939133\n",
            "1    1.083583\n",
            "2    1.228033\n",
            "3    1.372483\n",
            "4    1.516933\n",
            "Name: Time, dtype: float64\n",
            "\n",
            "After:\n",
            "0    18\n",
            "1    19\n",
            "2    20\n",
            "3    21\n",
            "4    22\n",
            "Name: Time, dtype: int64\n",
            "\n",
            "Processed dataset:\n",
            "        Date  Time    CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  \\\n",
            "0 2004-03-10    18  0.474000     1.302055  2.211236  0.242065       0.530761   \n",
            "1 2004-03-10    19  0.466273     1.028437  1.939383  0.182019       0.182278   \n",
            "2 2004-03-10    20  0.468849     1.460851  1.767687  0.172368       0.122335   \n",
            "3 2004-03-10    21  0.468849     1.361909  1.710454  0.177950       0.156878   \n",
            "4 2004-03-10    22  0.461122     0.940489  1.502988  0.112443      -0.301331   \n",
            "\n",
            "    NOx(GT)  PT08.S3(NOx)   NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)         T  \\\n",
            "0 -0.010117      1.088938  0.432257      0.845248     0.803763  0.088502   \n",
            "1 -0.254862      1.504305  0.266805      0.416137     0.016116  0.081558   \n",
            "2 -0.146086      1.392865  0.440136      0.403289     0.306551  0.049152   \n",
            "3  0.013192      1.233022  0.503165      0.498362     0.645129  0.028319   \n",
            "4 -0.146086      1.589855  0.455893      0.191731     0.408361  0.031791   \n",
            "\n",
            "         RH        AH  \n",
            "0  0.183379  0.194880  \n",
            "1  0.160436  0.194052  \n",
            "2  0.282964  0.194687  \n",
            "3  0.400610  0.195623  \n",
            "4  0.392311  0.195676  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c.Data splitting: Split data as 70% train and 30% test using train_test_split function."
      ],
      "metadata": {
        "id": "CdY1tea-_jl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IgAj48jfl4L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#For single feature\n",
        "X = df[['CO(GT)']]\n",
        "y = df['AH']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "b6QnuM5__qBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71449056-c514-4599-c36d-64023e96df10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (6549, 1)\n",
            "X_test shape: (2808, 1)\n",
            "y_train shape: (6549,)\n",
            "y_test shape: (2808,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# For multiple feature\n",
        "X = df[['CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)','PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)']]\n",
        "y = df['AH']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJifoJDk_MMB",
        "outputId": "0ec67964-9fb3-4591-9dae-002136ad15cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (6549, 9)\n",
            "X_test shape: (2808, 9)\n",
            "y_train shape: (6549,)\n",
            "y_test shape: (2808,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d.Fit model using fit function taking a single feature at a time and all independent features at a time.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d4CT0ceWtFKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_single_feature = X_train[['C6H6(GT)']]\n",
        "y_train_single_feature = y_train\n",
        "model_single_feature = LinearRegression()\n",
        "model_single_feature.fit(X_train_single_feature, y_train_single_feature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "UbMcA0BXtPSr",
        "outputId": "34ece831-5dfd-46a5-f6a4-170f6cdab1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_all_features  = LinearRegression()\n",
        "model_all_features .fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "kKEj_6l__pfd",
        "outputId": "bab0505d-0f09-4a40-d3c6-fa863a1dd5e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e.Report parameter values, training error and test error and model accuracy for Linear regression with single feature and multiple features."
      ],
      "metadata": {
        "id": "4FNDzyhttQE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "#NOTE: R2-score - To evaluate the goodness of fit of a regression model.\n",
        "\n",
        "# Single feature\n",
        "X_test_single_feature = X_test[['C6H6(GT)']]\n",
        "y_test_single_feature = y_test\n",
        "# parameter values\n",
        "coef = model_single_feature.coef_\n",
        "intercept = model_single_feature.intercept_\n",
        "# Calculating predicate values\n",
        "y_train_pred = model_single_feature.predict(X_train_single_feature)\n",
        "y_test_pred = model_single_feature.predict(X_test_single_feature)\n",
        "# training and test error\n",
        "train_error = mean_squared_error(y_train, y_train_pred)\n",
        "test_error = mean_squared_error(y_test, y_test_pred)\n",
        "# model accuracy\n",
        "r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Parameter values:\")\n",
        "print(\"Coefficient:\", coef)\n",
        "print(\"Intercept:\", intercept)\n",
        "print(\"\\nTraining Error:\", train_error)\n",
        "print(\"Test Error:\", test_error)\n",
        "print(\"R-squared (Model Accuracy):\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN9mPfwktRx5",
        "outputId": "6b526981-9ff6-4a2a-f5b6-2a608343b9f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter values:\n",
            "Coefficient: [0.98585899]\n",
            "Intercept: 0.0024334274633714885\n",
            "\n",
            "Training Error: 0.02985000657335495\n",
            "Test Error: 0.03254161048185446\n",
            "R-squared (Model Accuracy): 0.9675033474889237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For multiple feature\n",
        "# parameter values\n",
        "coef_all_features = model_all_features.coef_\n",
        "intercept_all_features = model_all_features.intercept_\n",
        "\n",
        "# Predict on training and testing data\n",
        "y_train_pred_all_features = model_all_features.predict(X_train)\n",
        "y_test_pred_all_features = model_all_features.predict(X_test)\n",
        "\n",
        "# Calculate training and test errors\n",
        "train_error_all_features = mean_squared_error(y_train, y_train_pred_all_features)\n",
        "test_error_all_features = mean_squared_error(y_test, y_test_pred_all_features)\n",
        "\n",
        "# Calculate R-squared (model accuracy)\n",
        "r2_all_features = r2_score(y_test, y_test_pred_all_features)\n",
        "\n",
        "# Print parameter values, training error, test error, and model accuracy\n",
        "print(\"Parameter values:\")\n",
        "print(\"Coefficient:\", coef_all_features)\n",
        "print(\"Intercept:\", intercept_all_features)\n",
        "print(\"\\nTraining Error:\", train_error_all_features)\n",
        "print(\"Test Error:\", test_error_all_features)\n",
        "print(\"R-squared (Model Accuracy):\", r2_all_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrcZd5jlA4WY",
        "outputId": "4bed7880-b6c9-4d3f-d77d-e350bce3558d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter values:\n",
            "Coefficient: [ 0.00239395 -0.01198363 -0.00312823  1.0876342  -0.18555708 -0.04382193\n",
            " -0.02395594  0.02896879  0.00117067]\n",
            "Intercept: 0.0006072525791409266\n",
            "\n",
            "Training Error: 0.0026779843396792487\n",
            "Test Error: 0.0033700267199065037\n",
            "R-squared (Model Accuracy): 0.9966346291517776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**B)Answer following questions (include question and answer as markdown cell in your notebook)**"
      ],
      "metadata": {
        "id": "ZqDcLw8-kq0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a.Provide a general multiple linear regression equation and explain all the terms."
      ],
      "metadata": {
        "id": "OQsWwdn7kwKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A multiple linear regression equation models the relationship between multiple independent variables (features) and a dependent variable (target).\n",
        "\n",
        "Equation:\n",
        "\n",
        "y = b+w1.x1+w2.x2+.......+wn.xn\n",
        "\n",
        "\n",
        "1.   y is the dependent variable (target) that we want to predict.\n",
        "2.   b is the y-intercept or constant term. It represents the expected mean value of y\n",
        "when all independent variables are set to zero. It is the value of y when all x variables are absent.\n",
        "3.   w1, w2,..., wn are the coefficients associated with each independent variable. They represent the change in the dependent variable y for a one-unit change in the corresponding independent variable x, holding all other variables constant. These are the parameters that the model learns during the training process.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UbNl2jgVk1Ay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "b.Explain the concept of a dummy variable and how such variables are calculated. Why is it necessary to convert nominal variables to dummy variables when performing linear regression?"
      ],
      "metadata": {
        "id": "KqXaZbzel6xR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dummy variable, also known as an indicator variable, is a binary variable used to represent categorical data in statistical models like linear regression. It's necessary to convert nominal variables to dummy variables when performing linear regression because linear regression requires numerical inputs, and nominal variables cannot be directly used in their original form.\n",
        "\n",
        "Here's how dummy variables are calculated and why they are necessary:\n",
        "\n",
        "* **Calculating Dummy Variables:**\n",
        "\n",
        "Suppose you have a nominal variable with k categories. To represent this nominal variable as dummy variables, you create k−1 binary variables.\n",
        "Each dummy variable represents one category of the nominal variable.\n",
        "For each observation, one of the dummy variables is set to 1 to indicate the category to which it belongs, and all other dummy variables are set to 0.\n",
        "Example:\n",
        "\n",
        "Suppose you have a nominal variable \"Color\" with categories \"Red,\" \"Green,\" and \"Blue.\"\n",
        "You create two dummy variables: \"Dummy_Red\" and \"Dummy_Green.\"\n",
        "If an observation has the color \"Red,\" the \"Dummy_Red\" variable would be 1, the \"Dummy_Green\" variable would be 0.\n",
        "If an observation has the color \"Green,\" the \"Dummy_Red\" variable would be 0, the \"Dummy_Green\" variable would be 1.\n",
        "\n",
        "*   **Necessity of Dummy Variables:**\n",
        "\n",
        "Linear regression models require numerical inputs. Nominal variables, such as categorical data, cannot be directly used in regression models.\n",
        "By converting nominal variables to dummy variables, we can represent categorical data numerically, allowing us to include them as predictors in regression models.\n",
        "Dummy variables also enable linear regression to capture the effect of categorical variables on the dependent variable by treating each category separately.\n",
        "\n",
        "*  **Avoiding Multicollinearity:**\n",
        "\n",
        "Including all\n",
        "k categories as separate variables could lead to multicollinearity, where one predictor can be linearly predicted from the others with a substantial degree of accuracy.\n",
        "By creating only\n",
        "k−1 dummy variables, we avoid perfect multicollinearity because the omitted category is the reference category against which the others are compared.\n",
        "In summary, dummy variables are essential in linear regression to represent categorical data numerically, enabling the model to incorporate the effects of categorical variables while avoiding multicollinearity."
      ],
      "metadata": {
        "id": "R-wf9Dral-nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "c.Explore and mention assumptions in linear regression with suitable explanation"
      ],
      "metadata": {
        "id": "2Jcr4Xp5my7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Linear regression relies on several assumptions for its validity:\n",
        "\n",
        "1. **Linearity:** The relationship between the independent variables and the dependent variable is linear. This means that the change in the dependent variable is proportional to the change in the independent variables.\n",
        "\n",
        "2. **Independence:** The observations in the dataset are independent of each other. There should be no correlation between the residuals (the differences between the observed and predicted values).\n",
        "\n",
        "3. **Homoscedasticity:** The variance of the residuals is constant across all levels of the independent variables. In other words, the spread of the residuals should remain constant as the values of the independent variables change.\n",
        "\n",
        "4. **Normality of Residuals:** The residuals should be normally distributed. This means that the errors should follow a normal distribution with a mean of 0.\n",
        "\n",
        "5. **No Multicollinearity:** The independent variables should not be highly correlated with each other. High multicollinearity can lead to unstable estimates of the coefficients.\n",
        "\n",
        "Violation of these assumptions can lead to biased and inefficient estimates of the regression coefficients, affecting the reliability and interpretability of the model. Therefore, it's essential to assess these assumptions and, if necessary, take appropriate measures to address any violations."
      ],
      "metadata": {
        "id": "dzRnnsMOnI5T"
      }
    }
  ]
}